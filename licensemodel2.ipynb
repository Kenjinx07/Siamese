{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc2ae0c",
   "metadata": {},
   "source": [
    "# 1. Dependencies and Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1a43d7-c92e-4e83-8bbc-27a2952cd988",
   "metadata": {
    "tags": [
     "***"
    ]
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import uuid\n",
    "import random\n",
    "import pytest\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf10e0c-ee5c-437f-b630-7376c41b3a1e",
   "metadata": {
    "tags": [
     "***"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f474c-47d5-4f7d-92bc-3a5e9a90ce2a",
   "metadata": {
    "tags": [
     "***"
    ]
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f25290",
   "metadata": {
    "tags": [
     "***"
    ]
   },
   "outputs": [],
   "source": [
    "POS_PATH = os.path.join('data', 'positive')\n",
    "NEG_PATH = os.path.join('data', 'negative')\n",
    "ANC_PATH = os.path.join('data', 'anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380c1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(POS_PATH)\n",
    "os.makedirs(NEG_PATH)\n",
    "os.makedirs(ANC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe4d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in os.listdir('lfw'):\n",
    "    for file in os.listdir(os.path.join('lfw', directory)):\n",
    "        EX_PATH = os.path.join('lfw', directory, file)\n",
    "        NEW_PATH = os.path.join(NEG_PATH, file)\n",
    "        os.replace(EX_PATH, NEW_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdc0357",
   "metadata": {},
   "source": [
    "# 2. Image Collection and Other Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930e66be-3c79-4daa-9ca1-d449180aca77",
   "metadata": {
    "tags": [
     "***"
    ]
   },
   "outputs": [],
   "source": [
    "def sharpen_image(image):\n",
    "    kernel = np.array([[-1, -1, -1],\n",
    "                       [-1, 9, -1],\n",
    "                       [-1, -1, -1]])\n",
    "\n",
    "    sharpened =cv2.filter2D(image, -1, kernel)\n",
    "    return sharpened\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    frame = frame[:1080,:1920, :]\n",
    "    \n",
    "    blurred_frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "    \n",
    "    more_blurred_frame = cv2.GaussianBlur(blurred_frame, (9, 9), 0)\n",
    "    \n",
    "    sharpened_frame = sharpen_image(more_blurred_frame)\n",
    "\n",
    "    if cv2.waitKey(10) & 0Xff == ord('a'):\n",
    "        imgname = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        cv2.imwrite(imgname, frame) \n",
    "            \n",
    "    if cv2.waitKey(10) & 0Xff == ord('p'):\n",
    "        imgname = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        cv2.imwrite(imgname, frame) \n",
    "    \n",
    "    if cv2.waitKey(10) & 0Xff == ord('n'):\n",
    "        imgname = os.path.join(NEG_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        cv2.imwrite(imgname, frame) \n",
    "    \n",
    "    cv2.imshow('Image Collection', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0Xff == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df16c887",
   "metadata": {},
   "source": [
    "* Optional: If image type is not '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e59b9f",
   "metadata": {
    "tags": [
     "***"
    ]
   },
   "outputs": [],
   "source": [
    "def rename_images(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            old_path = os.path.join(directory, filename)\n",
    "            new_filename = str(uuid.uuid1()) + os.path.splitext(filename)[1]\n",
    "            new_path = os.path.join(directory, new_filename)\n",
    "            os.rename(old_path, new_path)\n",
    "\n",
    "rename_images(POS_PATH)\n",
    "\n",
    "rename_images(ANC_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792266b8",
   "metadata": {},
   "source": [
    "# 2.x Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eed891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_aug(img):\n",
    "    data = []\n",
    "    for i in range(9):\n",
    "        img = tf.image.stateless_random_brightness(img, max_delta=0.02, seed=(1,2))\n",
    "        img = tf.image.stateless_random_contrast(img, lower=0.6, upper=1, seed=(1,3))\n",
    "        img = tf.image.stateless_random_flip_left_right(img, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        img = tf.image.stateless_random_jpeg_quality(img, min_jpeg_quality=90, max_jpeg_quality=100, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        img = tf.image.stateless_random_saturation(img, lower=0.9,upper=1, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "            \n",
    "        data.append(img)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982c464a",
   "metadata": {},
   "source": [
    "# 3. Data Setting and Image Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f665f2e",
   "metadata": {
    "tags": [
     "***"
    ]
   },
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(ANC_PATH+'\\\\*.jpg').take(2000)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH+'\\\\*.jpg').take(2000)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH+'\\\\*.jpg').take(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4691a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    img = tf.image.resize(img, (150, 300))\n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078aed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocess('data\\\\anchor\\\\21e9c4a2-0c86-11ef-82f2-010101010000.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d5d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.numpy().max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33eb605",
   "metadata": {
    "tags": [
     "***"
    ]
   },
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca295b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da8229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = samples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841336ed",
   "metadata": {
    "tags": [
     "***"
    ]
   },
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return(preprocess(input_img), preprocess(validation_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ff4cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = preprocess_twin(*example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab944ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df324fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420336a8",
   "metadata": {
    "tags": [
     "***"
    ]
   },
   "outputs": [],
   "source": [
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b99d6",
   "metadata": {
    "tags": [
     "***"
    ]
   },
   "outputs": [],
   "source": [
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(8)\n",
    "train_data = train_data.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c72ed",
   "metadata": {
    "tags": [
     "***"
    ]
   },
   "outputs": [],
   "source": [
    "test_data = data.skip(round(len(data)*.7))\n",
    "test_data = test_data.take(round(len(data)*.3))\n",
    "test_data = test_data.batch(8)\n",
    "test_data = test_data.prefetch(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddf1e09",
   "metadata": {},
   "source": [
    "# 4. Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c845311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(150,300,3), name='input_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eccc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = Conv2D(32, (7, 7), activation='relu')(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2155fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = MaxPooling2D(pool_size=(2,2))(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f094925",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = Flatten()(m1)\n",
    "d1 = Dense(128, activation='sigmoid')(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4505527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = Model(inputs=[inp], outputs=[d1], name='embedding_simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1412452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba6f670",
   "metadata": {
    "tags": [
     "***"
    ]
   },
   "outputs": [],
   "source": [
    "def make_embedding_simple():\n",
    "    inp = Input(shape=(150, 300, 3), name='input_image')\n",
    "    \n",
    "    c1 = Conv2D(32, (7, 7), activation='relu')(inp)\n",
    "    m1 = MaxPooling2D(pool_size=(2, 2))(c1)\n",
    "    f1 = Flatten()(m1)\n",
    "    d1 = Dense(128, activation='sigmoid')(f1)\n",
    "    \n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding_simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de45580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_simple = make_embedding_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f877a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_simple.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292fd612",
   "metadata": {},
   "source": [
    "# 4.2 Build Distance Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9eaf8b",
   "metadata": {
    "tags": [
     "***"
    ]
   },
   "outputs": [],
   "source": [
    "class L1Dist(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "    \n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "\n",
    "        input_embedding = tf.convert_to_tensor(input_embedding)\n",
    "        validation_embedding = tf.convert_to_tensor(validation_embedding)\n",
    "        \n",
    "        distances = tf.math.abs(input_embedding - validation_embedding)\n",
    "        return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4e6972",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = L1Dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1846b1e2",
   "metadata": {},
   "source": [
    "# 4.3 Make Siamese Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db3b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input(name='input_img', shape=(150,300,3))\n",
    "validation_image =Input(name='validation_img', shape=(150,300,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c00b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_embedding = embedding_simple(input_image)\n",
    "val_embedding = embedding_simple(validation_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce3221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_layer = L1Dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f74064",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = siamese_layer(inp_embedding, val_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4069ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Dense(1, activation='sigmoid')(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec7fdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d661bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model_simple = Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetworkSimple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f357e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model_simple.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b51124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model_simple():\n",
    "    input_image = Input(name='input_img', shape=(150, 300, 3))\n",
    "    validation_image = Input(name='validation_img', shape=(150, 300, 3))\n",
    "\n",
    "    embedding_simple = make_embedding_simple()\n",
    "\n",
    "    inp_embedding = embedding_simple(input_image)\n",
    "    val_embedding = embedding_simple(validation_image)\n",
    "\n",
    "    if isinstance(inp_embedding, list):\n",
    "        inp_embedding = inp_embedding[0]\n",
    "    if isinstance(val_embedding, list):\n",
    "        val_embedding = val_embedding[0]\n",
    "\n",
    "    siamese_layer = L1Dist()\n",
    "\n",
    "    distances = siamese_layer(inp_embedding, val_embedding)\n",
    "\n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "\n",
    "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetworkSimple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbecc991",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model_simple = make_siamese_model_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45871400",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model_simple.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7663f7fb",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf3866",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaca1b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3511136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model_simple=siamese_model_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52f189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = train_data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02446021",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = test_batch.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1= batch[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7bfdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image, validation_image = batch[:2]\n",
    "\n",
    "print(\"Shape before any operation:\", input_image.shape, validation_image.shape)\n",
    "\n",
    "input_image = tf.reshape(input_image, (-1, 150, 300, 3))\n",
    "validation_image = tf.reshape(validation_image, (-1, 150, 300, 3))\n",
    "\n",
    "print(\"Shape after reshaping:\", input_image.shape, validation_image.shape)\n",
    "\n",
    "yhat = siamese_model_simple.predict([input_image, validation_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d021b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (batch_1[:0], batch[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e63db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = batch_1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d34817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        X = (tf.expand_dims(batch[0], axis=0), tf.expand_dims(batch[1], axis=0))\n",
    "        y = tf.expand_dims(batch[2], axis=0)\n",
    "        yhat = siamese_model_simple(X, training=True)\n",
    "        \n",
    "        if len(yhat.shape) == 0:\n",
    "            yhat = tf.expand_dims(yhat, axis=0)\n",
    "\n",
    "        loss = binary_cross_loss(y, yhat)\n",
    "    \n",
    "    grad = tape.gradient(loss, siamese_model_simple.trainable_variables)\n",
    "    opt.apply_gradients(zip(grad, siamese_model_simple.trainable_variables))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c3c3da",
   "metadata": {},
   "source": [
    "5.1 Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15662eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320c9da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, start_epoch, EPOCHS):\n",
    "    for epoch in range(start_epoch, EPOCHS+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        \n",
    "        r = Recall()\n",
    "        p = Precision()\n",
    "        \n",
    "        for idx, batch in enumerate(data):\n",
    "            loss = train_step(batch)\n",
    "            \n",
    "            input_image, validation_image = batch[0], batch[1]\n",
    "            input_image = tf.reshape(input_image, [-1, 150, 300, 3])\n",
    "            validation_image = tf.reshape(validation_image, [-1, 150, 300, 3])\n",
    "            \n",
    "            yhat = siamese_model_simple.predict([input_image, validation_image])\n",
    "            \n",
    "            labels = tf.expand_dims(batch[2], axis=-1)\n",
    "            \n",
    "            r.update_state(labels, yhat)\n",
    "            p.update_state(labels, yhat)\n",
    "            progbar.update(idx+1)\n",
    "        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n",
    "        \n",
    "        if epoch % 5 == 0: \n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab9675",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa68361",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "\n",
    "start_epoch = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab6ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(data, start_epoch, EPOCHS) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fedd93f",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04076391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0473ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input, test_val, y_true = test_data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba73331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = siamese_model_simple.predict([test_input, test_val])\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40542b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[1 if prediction > 0.5 else 0 for prediction in y_hat.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca942da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc5dd35",
   "metadata": {},
   "source": [
    "6.2 Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873ba77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Precision()\n",
    "m.update_state(y_true, y_hat)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f828c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Recall()\n",
    "m.update_state(y_true, y_hat)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f039641",
   "metadata": {},
   "source": [
    "6.3 Visual Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b1570",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(test_input[2])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(test_val[2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21bff2b",
   "metadata": {},
   "source": [
    "## 7. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a4de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model_simple.save('licenseIDmodel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3f287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('licenseIDmodel.keras', custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41883b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([test_input, test_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371ba578",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e349a3",
   "metadata": {},
   "source": [
    "## 8. Real Time Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46276bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(frame, model, detection_threshold, verification_threshold):\n",
    "    results = []\n",
    "    for image in os.listdir(os.path.join('application_data','verification_images')):\n",
    "        input_img = preprocess(os.path.join('application_data', 'input_image', 'input_image.jpg'))\n",
    "        validation_img = preprocess(os.path.join('application_data', 'verification_images', image))\n",
    "\n",
    "        result = model.predict(list(np.expand_dims([input_img, validation_img], axis=1)))\n",
    "        results.append(result)\n",
    "\n",
    "    detection = np.sum(np.array(results) > detection_threshold)\n",
    "    verification = detection /  len(os.listdir(os.path.join('application_data', 'verification_images')))\n",
    "    verified = verification > verification_threshold\n",
    "\n",
    "    return results, verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc43680",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    frame = frame[:1080,:1920, :]\n",
    "\n",
    "    cv2.imshow('verification', frame)\n",
    "\n",
    "    if cv2.waitKey(5) & 0xFF == ord('v'):\n",
    "        cv2.imwrite(os.path.join('application_data', 'input_image', 'input_image.jpg'), frame)\n",
    "        results, verified = verify(frame, model, detection_threshold=0.9, verification_threshold=0.7)\n",
    "        print(verified)\n",
    "\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efacdf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.squeeze(results) > 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b35b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "42/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1322f8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
